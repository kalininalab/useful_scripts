# Romans Scripts

More detailed description of the scripts in this folder.

For more detailed description of the actual code, visit the scripts.

### Scripts

##### fold.py [Code](fold.py)
This is a script that can run AlphaFold2, OpenFold, and OmegaFold on some query data.
For the arguments, please refer to the `-h` option of the script.

In order to execute the script, you need to install and activte this [conda environment](fold_env.yml). 
Additionally, you need to clone the [OpenFold repo](https://github.com/aqlaboratory/openfold) and the 
[OmegaFold repo](https://github.com/HeliXonProtein/OmegaFold.git) from github. You don't need to install them, but you 
need to download the weights for all three models.

How to download the weights:
* OmegaFold will do this automatically, just specify the `--omegafold` parameter to the directory where to download.
* AlphaFold
* OpenFold

<b>REMARK: THE COMPLETE STEPS ARE NOT TESTED SO FAR. I WROTE THIS SCRIPT BASED ON EXISTING AND TESTED INSTALLATIONS OF ALL 
THREE TOOLS.</b>

##### run_multifold.py [Code](run_multifold.py)
This script is a bit more tricky. You have to move it to the root-directory of Sanjay's Docker-free alphafold 
repository [Link](https://github.com/kalininalab/alphafold_non_docker). The arguments are currently quite limited:
* directory of data where to perform the database search (same as Sanjay's "-d" argument)
* directory with fasta-files for every query sequence
* directory for the output of the results, every fasta sequence will get a subfolder in that directory
* timestamp for the database search (same as Sanjay's "-t" argument)
* Number of kernels you want to use

Some further notes:
* So far, this is only tested for single sequences, not entire proteins (only homomer folding)
* It is currently not possible to give set argument to enable GPU based computations
* In the output-directory will be a tmp-folder storing all files generated by alphafold, not only the final PDB file 
  but also the models and some other stuff

##### pubchem_crawler.py [Code](pubchem_crawler.py)
This is a script to scan and download the entire [PubChem-Compound database](https://pubchem.ncbi.nlm.nih.gov/). There 
are no arguments to provide, as you will need to adapt the filtering of the script, you can also directly change the 
directories and filenames as you need it.

From the result of this script, you have a tsv file of PubChem's CompoundIDs (CID) and the according SMILES string for 
every compound in the PubChem database that passes your filters. 

!!! ATTENTION: THIS SCRIPT WILL NEED 2 TB OF MEMORY TO RUN !!! 

##### chain.py [Code](chain.py)
Very simple: I tried many ways to extract a specific chain from a pdb-file, but only this one really worked out for me.
The arguments are as follows:
* Name of the PDB molecule in the file
* Path to the pdb-file to extract the chain from
* Chain to be extracted
* Path to the output file to store the chain in

https://stackoverflow.com/questions/51187658/markdown-reference-to-section-from-another-file